{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_z3DlnC0y-I"
      },
      "source": [
        "# Download Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGaRIx2105Na"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from json import loads as parse_json\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import io\n",
        "import os\n",
        "\n",
        "# Changing the option to show a dataframe not 'in-line'\n",
        "pd.set_option('display.expand_frame_repr', False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gxc1CC5vCod",
        "outputId": "518ed245-2158-4a81-8e99-f05f23ec518c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['florida_region_query.csv', 'multimedia.txt', 'occurrence.txt', 'Region_Downloading_Pipeline.ipynb']\n",
            "florida_region_query.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Checking that my drive is connected\n",
        "dir = os.listdir()\n",
        "print(dir)\n",
        "\n",
        "csv_file = [i for i in dir if '.csv' in i][0]\n",
        "print(csv_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1svgtrI07ov"
      },
      "source": [
        "## Reading Query Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIDOXTrGuvaf",
        "outputId": "7deedd26-b5b5-46a5-aa8f-624dd4dad22d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of query:  (1307, 22)\n",
            "Shape of media:  (1468200, 12)\n",
            "Shape of occur:  (1036564, 202)\n",
            "unique ids in occur:  1036564\n",
            "unique ids in media:  709815\n"
          ]
        }
      ],
      "source": [
        "# Loading CSVs from google drive\n",
        "try:\n",
        "    query = pd.read_csv(csv_file, sep=',', encoding='latin-1', dtype=object).dropna(axis=1, how='all') # uses taxonKey for 'class'\n",
        "except:\n",
        "    query = pd.read_csv(csv_file, sep='\\t', encoding='latin-1', dtype=object).dropna(axis=1, how='all') # uses taxonKey for 'class'\n",
        "\n",
        "\n",
        "print(\"Shape of query: \", query.shape)\n",
        "# print(query.sort_values('numberOfOccurrences'))\n",
        "\n",
        "media = pd.read_csv('multimedia.txt', sep='\\t', encoding='latin-1', dtype=object, on_bad_lines='skip').dropna(axis=1, how='all') # uses gbifID for 'occurrence'\n",
        "print(\"Shape of media: \", media.shape)\n",
        "\n",
        "occur = pd.read_csv('occurrence.txt', sep='\\t', encoding='latin-1', dtype=object, on_bad_lines='skip').dropna(axis=1, how='all') # uses taxonKey for 'class' and gbifIF for 'occurrence'\n",
        "print(\"Shape of occur: \", occur.shape)\n",
        "\n",
        "# unique taxons\n",
        "occur_count = occur.nunique()\n",
        "media_count = media.nunique()\n",
        "print('unique ids in occur: ', occur_count[\"gbifID\"])\n",
        "print('unique ids in media: ', media_count[\"gbifID\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1de7u871GKJ"
      },
      "source": [
        "## Managing the Loaded Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67Amqrvv0GM2",
        "outputId": "0622511a-7c83-4e28-d229-82c7717f9362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of occur_media:  (1468010, 213)\n",
            "<bound method NDFrame.head of 0          https://inaturalist-open-data.s3.amazonaws.com...\n",
            "1          https://inaturalist-open-data.s3.amazonaws.com...\n",
            "2          https://inaturalist-open-data.s3.amazonaws.com...\n",
            "3          https://inaturalist-open-data.s3.amazonaws.com...\n",
            "4          https://inaturalist-open-data.s3.amazonaws.com...\n",
            "                                 ...                        \n",
            "1468005    https://svampe.databasen.org/uploads/2022-1027...\n",
            "1468006    https://svampe.databasen.org/uploads/2022-1027...\n",
            "1468007    https://svampe.databasen.org/uploads/2022-1027...\n",
            "1468008    https://svampe.databasen.org/uploads/2022-1027...\n",
            "1468009    http://specify.ugrasu.ru:8080/fileget?coll=Fun...\n",
            "Name: identifier_y, Length: 1468010, dtype: object>\n"
          ]
        }
      ],
      "source": [
        "# combine the dataframes based on matching id\n",
        "occur_media = pd.merge(occur, media, on=\"gbifID\", how=\"inner\")\n",
        "\n",
        "print(\"Shape of occur_media: \", occur_media.shape)\n",
        "print(occur_media['identifier_y'].head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjJKIBeG0TCL",
        "outputId": "822b55d3-6767-48e2-a7c4-9985c83d1384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      taxonKey           genus                      species numberOfOccurrences\n",
            "0      2548311        Trametes          Trametes versicolor                1879\n",
            "2      5243168   Chlorophyllum     Chlorophyllum molybdites                1257\n",
            "3      2553087         Stereum          Stereum complicatum                1183\n",
            "4      5249599    Cantharellus    Cantharellus cinnabarinus                1164\n",
            "5      5248508        Hericium           Hericium erinaceus                1139\n",
            "...        ...             ...                          ...                 ...\n",
            "1035   3363661           Fomes            Fomes fomentarius                   1\n",
            "1033   2549043         Erastia         Erastia salmonicolor                   1\n",
            "1032   8252570        Entoloma            Entoloma watsonii                   1\n",
            "1031   8095923        Entoloma           Entoloma strictius                   1\n",
            "1306  10792674  Zhuliangomyces  Zhuliangomyces subillinitus                   1\n",
            "\n",
            "[1214 rows x 4 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bulld\\AppData\\Local\\Temp\\ipykernel_18088\\1976546659.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  taxons = query.iloc[sort_order][query['numberOfOccurrences'].astype('int32') > 0][::-1].dropna(subset=['species'])\n"
          ]
        }
      ],
      "source": [
        "# sort using the values as numbers, not objects/strings\n",
        "sort_order = query['numberOfOccurrences'].astype('int32').argsort() \n",
        "\n",
        "# sort the queries by occurence number and then reverse it because argsort is always ascending order\n",
        "taxons = query.iloc[sort_order][query['numberOfOccurrences'].astype('int32') > 0][::-1].dropna(subset=['species']) \n",
        "\n",
        "print(taxons[['taxonKey','genus', 'species', 'numberOfOccurrences']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX609q5d1Ylb"
      },
      "source": [
        "## Generating Links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Qxzigk0Ua0",
        "outputId": "f3940ac3-1f80-4993-f1c7-a515c25fae15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Species\t 524.0\n",
            "Number of rows:\t 157200 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "number_of_images = 300\n",
        "fail_count = 0 # number of species without enough images\n",
        "\n",
        "# initialize the empty dataframe\n",
        "links = pd.DataFrame(columns=['key',  'species', 'link'])\n",
        "\n",
        "# loop through and grab n rows per taxon\n",
        "for i in range(len(taxons)): \n",
        "\n",
        "    # subset occurences to get just the first n matching rows\n",
        "    current_taxon = taxons['taxonKey'].iloc[i]\n",
        "    subset = occur_media.loc[occur_media['taxonKey'] == current_taxon].dropna(subset=['identifier_y'])\n",
        "\n",
        "    # initialize a (n, 3) array to fill\n",
        "    arr = np.ndarray((number_of_images, 3), dtype='object')\n",
        "    count = 0\n",
        "\n",
        "    if len(subset) > number_of_images:\n",
        "        for j in range(len(subset)):\n",
        "\n",
        "            # get the file extension \n",
        "            url = subset.iloc[j]['identifier_y']\n",
        "            root, ext = os.path.splitext(url)\n",
        "\n",
        "            # filter out any files that dont have .jpg or .jpeg extensions for uniformity\n",
        "            if ext == '.jpg' or ext == '.jpeg':\n",
        "                \n",
        "                # take the useful values from the current row and insert them into the ndarray\n",
        "                row = subset.iloc[j][['taxonKey', 'species', 'identifier_y']]\n",
        "                arr[count] = [row['taxonKey'], row['species'], row['identifier_y']]\n",
        "                count += 1\n",
        "\n",
        "            # filled array\n",
        "            if count >= number_of_images:\n",
        "                count = 0\n",
        "                break\n",
        "\n",
        "        # convert the filled ndarray into a dataframe \n",
        "        sub = pd.DataFrame(arr, columns=['key',  'species', 'link'])\n",
        "\n",
        "        # concatenate the dataframe\n",
        "        links = pd.concat([links, sub])\n",
        "        \n",
        "    # else:\n",
        "    #     fail_count += 1\n",
        "\n",
        "# reset and drop the indices        \n",
        "links = links.reset_index()[['key',  'species', 'link']]\n",
        "\n",
        "print('Number of Species\\t', links.shape[0] / number_of_images)\n",
        "print('Number of rows:\\t', links.shape[0], '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "PuoZOXDI0dOc"
      },
      "outputs": [],
      "source": [
        "# run this to redownload the aggregated links file\n",
        "links.to_csv('links.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQswm8sr1j4j"
      },
      "source": [
        "## Reading from Links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xcrl2Ap0ojO",
        "outputId": "1992805f-688a-45e7-e70c-525201a44cbd"
      },
      "outputs": [],
      "source": [
        "nkeys = links['key'].value_counts()\n",
        "print('Unique keys:\\t', len(nkeys))\n",
        "\n",
        "nspecies = links['species'].value_counts()\n",
        "print('Unique species:\\t', len(nspecies), '\\n')\n",
        "\n",
        "keys_species = links.groupby(['key','species']).size().reset_index().rename(columns={0:'count'})\n",
        "print(keys_species[['species']].value_counts().sort_values().tail())\n",
        "\n",
        "print('\\nIDs for duplicate species (\"Laetiporus sulphureus\"): ', links[links['species'] == 'Laetiporus sulphureus']['key'].unique())\n",
        "\n",
        "links = links[links['key'] != '2542235']\n",
        "\n",
        "print('\\n\\nAfter Removal:')\n",
        "print('\\nIDs for duplicate species (\"Laetiporus sulphureus\"): ', links[links['species'] == 'Laetiporus sulphureus']['key'].unique())\n",
        "\n",
        "nkeys = links['key'].value_counts()\n",
        "print('\\nUnique keys:\\t', len(nkeys))\n",
        "\n",
        "nspecies = links['species'].value_counts()\n",
        "print('Unique species:\\t', len(nspecies))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2YO0lVr1qev"
      },
      "source": [
        "## Downloading the Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-cxpojB0pxB"
      },
      "outputs": [],
      "source": [
        "dir = os.listdir()\n",
        "print(dir)\n",
        "if 'images' not in dir:\n",
        "    os.mkdir('images/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-SCELZn0tUL"
      },
      "outputs": [],
      "source": [
        "for key in links['key'].unique():\n",
        "    subset = links[links['key'] == key]\n",
        "    output_dir = 'images/'\n",
        "    count = 0\n",
        "    species_name = subset['species'].unique()[0].replace(' ', '_')\n",
        "\n",
        "    print(species_name)\n",
        "\n",
        "    # print(subset)\n",
        "\n",
        "    for link in links[links['key'] == key]['link']:\n",
        "        try:\n",
        "            image = requests.get(link).content\n",
        "            output_file = os.path.join(output_dir, species_name + '_' + str(count) + '.jpg')\n",
        "            # print(output_file)\n",
        "            with open(output_file, 'wb') as writer:\n",
        "                writer.write(image)\n",
        "\n",
        "            # FILE.download(output_file)\n",
        "\n",
        "        except Exception as e: \n",
        "            print(e)\n",
        "        \n",
        "        finally:\n",
        "            count += 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
