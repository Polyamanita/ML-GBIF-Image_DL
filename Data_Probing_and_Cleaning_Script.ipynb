{"cells":[{"cell_type":"markdown","metadata":{"id":"Pnw5tQnN_ft6"},"source":["# GBIF Testing\n"]},{"cell_type":"markdown","metadata":{"id":"DBkTJ9u0McOg"},"source":["# Kingdom: \tFungi\n","### Division: \t    Basidiomycota\n","### Subdivision: \tAgaricomycotina\n","### Class: \t        Agaricomycetes"]},{"cell_type":"markdown","metadata":{"id":"f49iDlcZNTE5"},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4633,"status":"ok","timestamp":1669416599540,"user":{"displayName":"WheatDaddy_","userId":"01237282081092462010"},"user_tz":300},"id":"8uA2MmPcKR3v","outputId":"f48b4086-948d-4c07-ea3d-4a2513d03123"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pygbif in /usr/local/lib/python3.7/dist-packages (0.6.1)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pygbif) (1.4.4)\n","Requirement already satisfied: requests>2.7 in /usr/local/lib/python3.7/dist-packages (from pygbif) (2.23.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pygbif) (3.2.2)\n","Requirement already satisfied: geojson-rewind in /usr/local/lib/python3.7/dist-packages (from pygbif) (1.0.3)\n","Requirement already satisfied: geomet in /usr/local/lib/python3.7/dist-packages (from pygbif) (1.0.0)\n","Requirement already satisfied: requests-cache in /usr/local/lib/python3.7/dist-packages (from pygbif) (0.9.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>2.7->pygbif) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>2.7->pygbif) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>2.7->pygbif) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>2.7->pygbif) (2022.9.24)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from geomet->pygbif) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from geomet->pygbif) (1.15.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygbif) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygbif) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygbif) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygbif) (3.0.9)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygbif) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->pygbif) (4.1.1)\n","Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.7/dist-packages (from requests-cache->pygbif) (22.2.0)\n","Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.7/dist-packages (from requests-cache->pygbif) (22.1.0)\n","Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.7/dist-packages (from requests-cache->pygbif) (1.4.3)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.7/dist-packages (from cattrs>=22.2->requests-cache->pygbif) (1.0.4)\n"]}],"source":["!pip install pygbif"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3847,"status":"ok","timestamp":1669416603384,"user":{"displayName":"WheatDaddy_","userId":"01237282081092462010"},"user_tz":300},"id":"7SQu26RZK8An","outputId":"bc45706b-a883-4259-ae88-c591954b2bde"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n","/content/gdrive/MyDrive/Mushroom_Data\n"]},{"output_type":"execute_result","data":{"text/plain":["['region_query.csv',\n"," 'occurrence.tsv',\n"," 'multimedia.tsv',\n"," 'GBIF_Playground.ipynb',\n"," 'multimedia (1).gsheet',\n"," 'region_query.gsheet',\n"," 'links.csv',\n"," 'links.gsheet']"]},"metadata":{},"execution_count":2}],"source":["import pygbif.occurrences as occ\n","import pygbif as pg\n","from json import loads as parse_json\n","import json\n","import pandas as pd\n","import numpy as np\n","import requests\n","import io\n","import os\n","\n","# Changing the option to show a dataframe not 'in-line'\n","pd.set_option('display.expand_frame_repr', False)\n","\n","# Connecting to my drive\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive/', force_remount=True)\n","%cd gdrive/MyDrive/Mushroom_Data\n","\n","# Checking that my drive is connected\n","os.listdir()"]},{"cell_type":"markdown","metadata":{"id":"m8jZP6DgKNnS"},"source":["# Trying to use pygbif\n","\n","This was our initial attempt to use pygbif to gather the images from the GBIF database. We realized very quickly, however, that this wouldnt work out since they have a capped number of results for any query using the automated APIs as well as being excruciatingly slow to even collect and filter using this method. Instead we had to make an account and then a query via their website and download the results from there.\n","\n","API: https://pygbif.readthedocs.io/en/latest/intro/install.html"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2514,"status":"ok","timestamp":1669416605895,"user":{"displayName":"WheatDaddy_","userId":"01237282081092462010"},"user_tz":300},"id":"0--lrvwVOXpO","outputId":"7c66a3b1-9171-4dc0-9459-3f075c040b2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["2524102\n"]}],"source":["# region = \"POLYGON((-80.84917 24.20293,-80.01938 24.59512,-79.63128 26.09898,-79.42511 27.17836,-80.63179 31.09126,-75.41786 34.72027,-74.41965 36.59897,-80.11633 36.64279,-83.25188 36.64584,-87.28004 36.67774,-88.10162 36.70167,-88.08966 36.51821,-89.6346 36.59016,-90.04039 35.68417,-90.40183 35.04352,-90.82846 34.45193,-91.29241 33.66984,-91.11607 32.38428,-91.61095 31.46846,-91.71903 30.97357,-89.80207 30.95082,-89.87033 30.72329,-89.68261 30.19996,-88.82936 30.16014,-86.44589 29.87155,-84.32692 29.3511,-83.65777 29.16523,-82.65404 26.11688,-83.29368 24.74936,-83.01713 23.99761,-80.84917 24.20293))\"\n","\n","# key = pg.species.name_backbone(name = \"agaricomycetes\", rank=\"class\")['usageKey']\n","# key = pg.species.name_backbone(name = \"Phallus\", rank=\"genus\")['usageKey']\n","# print(key)\n","# region_results = occ.search(taxonKey = key, geometry= region, mediaType = 'StillImage')['results']\n","\n","# species = []\n","# len_iter = len(region_results)\n","# page = 1\n","\n","\n","# while len_iter > 0: # per page\n","#     print(f'pages: {page}')\n","\n","#     for i in range(len_iter): # per page item\n","#         if region_results[i]['scientificName'] not in species:\n","#             species.append(region_results[i]['scientificName'])\n","\n","#     region_results = occ.search(geometry= region, mediaType = 'StillImage', offset = 300 * page)['results']\n","#     len_iter = len(region_results)\n","#     page += 1\n","\n","#     if page > 10:\n","#         break\n","\n","# print(f'pages: {page}')\n","# print(f'species: {species}')\n","\n","# key_1 = pg.species.name_backbone(name = \"Amanita muscaria\", rank=\"species\")['usageKey']\n","# key_2 = pg.species.name_backbone(name = \"Schizophyllum commune\", rank=\"species\")['usageKey']\n","# payload = occ.search(geometry= region, taxonKey = key_1, limit = 302, mediaType = 'StillImage')\n","\n","# print(len(payload['results']))\n","\n","# json_object = json.dumps(payload, indent=4)\n","\n","# with open(\"example_query.json\", \"w\") as outfile:\n","#     outfile.write(json_object)\n","\n","# print(f'species: {len(species)}')\n","# print(f'pages: {page}')\n","\n","# Wow! jk"]},{"cell_type":"markdown","metadata":{"id":"sUBu_SMFvW6k"},"source":["# GBIF Download Citation:\n","GBIF.org (21 November 2022) GBIF Occurrence Download  https://doi.org/10.15468/dl.pjkxtn"]},{"cell_type":"markdown","metadata":{"id":"vqwx9hkDveuB"},"source":["# Loading the CSVs from the Occurence Download\n","\n","I downloaded a CSV containing about ~56,000 occurences of images within The Agaricomycetes taxon that are also withing our bounding polygon. I specified human observation, but 'preserved specimens' may also petentially be viable, however many of those are using plain backgrounds and wouldn't really match 'real data' scenarios."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8876,"status":"ok","timestamp":1669416614769,"user":{"displayName":"WheatDaddy_","userId":"01237282081092462010"},"user_tz":300},"id":"lRJuUvG2mDgE","outputId":"f59debaa-e522-407a-b3e9-b3b02987214b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of query:  (1307, 22)\n","Shape of media:  (121071, 10)\n","Shape of occur:  (56194, 95)\n","unique ids in occur:  56194\n","unique ids in media:  56194\n"]}],"source":["# Loading CSVs from google drive\n","query = pd.read_csv('region_query.csv', sep=',', encoding='latin-1', dtype=object).dropna(axis=1, how='all') # uses taxonKey for 'class'\n","media = pd.read_csv('multimedia.tsv', sep='\\t', encoding='latin-1', dtype=object).dropna(axis=1, how='all') # uses gbifID for 'occurrence'\n","occur = pd.read_csv('occurrence.tsv', sep='\\t', encoding='latin-1', dtype=object).dropna(axis=1, how='all') # uses taxonKey for 'class' and gbifIF for 'occurrence'\n","\n","# checking their sizes\n","print(\"Shape of query: \", query.shape)\n","print(\"Shape of media: \", media.shape)\n","print(\"Shape of occur: \", occur.shape)\n","\n","# unique taxons\n","occur_count = occur.nunique()\n","media_count = media.nunique()\n","print('unique ids in occur: ', occur_count[\"gbifID\"])\n","print('unique ids in media: ', media_count[\"gbifID\"])"]},{"cell_type":"markdown","metadata":{"id":"wTGjPDx-09gn"},"source":["# Data Transformations"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":353,"status":"ok","timestamp":1669416615113,"user":{"displayName":"WheatDaddy_","userId":"01237282081092462010"},"user_tz":300},"id":"_VFjH61KBqY-","outputId":"f296829e-1b4b-4bed-97b4-53d183fbc13f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of occur_media:  (121071, 104)\n","<bound method NDFrame.head of 0         https://inaturalist-open-data.s3.amazonaws.com...\n","1         https://inaturalist-open-data.s3.amazonaws.com...\n","2         https://inaturalist-open-data.s3.amazonaws.com...\n","3         https://inaturalist-open-data.s3.amazonaws.com...\n","4         https://inaturalist-open-data.s3.amazonaws.com...\n","                                ...                        \n","121066    https://inaturalist-open-data.s3.amazonaws.com...\n","121067    https://inaturalist-open-data.s3.amazonaws.com...\n","121068    https://inaturalist-open-data.s3.amazonaws.com...\n","121069    https://inaturalist-open-data.s3.amazonaws.com...\n","121070    https://inaturalist-open-data.s3.amazonaws.com...\n","Name: identifier_y, Length: 121071, dtype: object>\n"]}],"source":["# combine the dataframes based on matching id\n","occur_media = pd.merge(occur, media, on=\"gbifID\", how=\"inner\")\n","\n","print(\"Shape of occur_media: \", occur_media.shape)\n","print(occur_media['identifier_y'].head)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1669416615113,"user":{"displayName":"WheatDaddy_","userId":"01237282081092462010"},"user_tz":300},"id":"cnj5DReJQwVF","outputId":"4e002568-8722-4795-a6e1-1c0d575a116f"},"outputs":[{"output_type":"stream","name":"stdout","text":["    taxonKey          genus                    species numberOfOccurrences\n","0    2548311       Trametes        Trametes versicolor                1879\n","2    5243168  Chlorophyllum   Chlorophyllum molybdites                1257\n","3    2553087        Stereum        Stereum complicatum                1183\n","4    5249599   Cantharellus  Cantharellus cinnabarinus                1164\n","5    5248508       Hericium         Hericium erinaceus                1139\n","..       ...            ...                        ...                 ...\n","111  2524071    Pseudocolus     Pseudocolus fusiformis                 104\n","112  2554333       Geastrum          Geastrum saccatum                 102\n","113  9655343        Amanita          Amanita lavendula                 101\n","114  2543487    Ischnoderma      Ischnoderma resinosum                 101\n","115  5241399    Volvariella      Volvariella bombycina                 101\n","\n","[109 rows x 4 columns]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n","  \"\"\"\n"]}],"source":["# sort using the values as numbers, not objects/strings\n","sort_order = query['numberOfOccurrences'].astype('int32').argsort() \n","\n","# sort the queries by occurence number and then reverse it because argsort is always ascending order\n","taxons = query.iloc[sort_order][query['numberOfOccurrences'].astype('int32') > 99][::-1].dropna(subset=['species']) \n","\n","print(taxons[['taxonKey','genus', 'species', 'numberOfOccurrences']])"]},{"cell_type":"markdown","metadata":{"id":"m0H5dwP0P30h"},"source":["## Filtering links to the selected species"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1NOFcUJcJru0","executionInfo":{"status":"ok","timestamp":1669417281535,"user_tz":300,"elapsed":8892,"user":{"displayName":"WheatDaddy_","userId":"01237282081092462010"}},"outputId":"55b3dcc4-fc6a-439c-a226-0c11a37fd104"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Number of rows:\t 10900 \n","\n","           key                species                                               link\n","10895  5241399  Volvariella bombycina  https://inaturalist-open-data.s3.amazonaws.com...\n","10896  5241399  Volvariella bombycina  https://inaturalist-open-data.s3.amazonaws.com...\n","10897  5241399  Volvariella bombycina  https://inaturalist-open-data.s3.amazonaws.com...\n","10898  5241399  Volvariella bombycina  https://inaturalist-open-data.s3.amazonaws.com...\n","10899  5241399  Volvariella bombycina  https://inaturalist-open-data.s3.amazonaws.com...\n"]}],"source":["# initialize the empty dataframe\n","links = pd.DataFrame(columns=['key',  'species', 'link'])\n","\n","# loop through and grab 100 rows per taxon\n","for i in range(len(taxons)): \n","\n","    # subset occurences to get just the first 100 matching rows\n","    current_taxon = taxons['taxonKey'].iloc[i]\n","    subset = occur_media.loc[occur_media['taxonKey'] == current_taxon].dropna(subset=['identifier_y'])\n","\n","    # initialize a (100, 3) array to fill\n","    arr = np.ndarray((100, 3), dtype='object')\n","    count = 0\n","\n","    for j in range(len(subset)):\n","\n","        # get the file extension \n","        url = subset.iloc[j]['identifier_y']\n","        root, ext = os.path.splitext(url)\n","\n","        # filter out any files that dont have .jpg or .jpeg extensions for uniformity\n","        if ext == '.jpg' or ext == '.jpeg':\n","            \n","            # take the useful values from the current row and insert them into the ndarray\n","            row = subset.iloc[j][['taxonKey', 'species', 'identifier_y']]\n","            arr[count] = [row['taxonKey'], row['species'], row['identifier_y']]\n","            count += 1\n","\n","        # filled array\n","        if count >= 100:\n","            count = 0\n","            break\n","\n","    # convert the filled ndarray into a dataframe \n","    sub_100 = pd.DataFrame(arr, columns=['key',  'species', 'link'])\n","\n","    # concatenate the dataframe\n","    links = pd.concat([links, sub_100])\n","\n","# reset and drop the indices        \n","links = links.reset_index()[['key',  'species', 'link']]\n","\n","print('\\n\\nNumber of rows:\\t', links.shape[0], '\\n')\n","print(links.tail())"]},{"cell_type":"markdown","source":["# The CSV Download"],"metadata":{"id":"bZnmmPdmF-qk"}},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":211,"status":"ok","timestamp":1669417287066,"user":{"displayName":"WheatDaddy_","userId":"01237282081092462010"},"user_tz":300},"id":"nRrFa4OgeZZA"},"outputs":[],"source":["# run this to redownload the aggregated links file\n","links.to_csv('links.csv', index=False)"]}],"metadata":{"colab":{"collapsed_sections":["f49iDlcZNTE5"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}